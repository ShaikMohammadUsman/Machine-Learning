{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN(Cats vs Dogs).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1csAz4bOPAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d03e1214-1c37-4402-c90c-4b2cc8822956"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1N3m9dqOSra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea5491b4-4f62-4d3d-b697-28e240a883e4"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img,array_to_img"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjxA42EYXPgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen=ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvr8bXyzYKDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import array_to_img,img_to_array,load_img,ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YfUdOROYtEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img=load_img('/content/drive/My Drive/Cats and Dogs/Cats/cat.0.jpg') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLxvY9Vgd-N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=img_to_array(img)\n",
        "x=x.reshape((1,) + x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbIhb8ngeYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='preview', save_prefix='/content/drive/My Drive/Cats and Dogs/Cats/cat.0.jpg', save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6mVJgt6jU61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWfbLDjfpb8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load_img('/content/drive/My Drive/Cats and Dogs/Cats/cat.0.jpg')  # this is a PIL image\n",
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='/content/drive/My Drive/dataaugmentedcats', save_prefix='aug_cat', save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-KbwUORpysp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs='/content/drive/My Drive/Cats/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AaDYYSH5FtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMutRb0NyliQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COP302yCymMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMAjV8wUymKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUsvJRRGymHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5UFaJKaymAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4WHtwP7yl9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5Zy-jDyl6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbhXE1jkyl3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modules to be imported\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8KamXQyvFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBmhA0lyzj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data_dir = '/content/drive/My Drive/Cats and Dogs/Cats','/content/drive/My Drive/Cats and Dogs/Dogs'\n",
        "train_data_dir = '/content/drive/My Drive/Cats and Dogs'\n",
        "validation_data_dir = '/content/drive/My Drive/Test(750imgs)'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 750\n",
        "epochs = 50\n",
        "batch_size = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx5aL3s2zZPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, 150, 150)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3JISL5Jz5nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOoL1x4cz77G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR-fCaAd0CHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c2cbd6b-1b7d-43ab-c725-4d366e2a5e34"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2022 images belonging to 2 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxQYKH820pLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b8d3276-bd91-48d7-bdf3-ed4e50ab09fb"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "133/133 [==============================] - 883s 7s/step - loss: 0.7019 - accuracy: 0.5407\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 76s 572ms/step - loss: 0.6774 - accuracy: 0.5994\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.6382 - accuracy: 0.6551\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.6213 - accuracy: 0.6732\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.5901 - accuracy: 0.6898\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.5704 - accuracy: 0.7199\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5531 - accuracy: 0.7209\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.5411 - accuracy: 0.7299\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5220 - accuracy: 0.7494\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5183 - accuracy: 0.7516\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5122 - accuracy: 0.7560\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5008 - accuracy: 0.7600\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4923 - accuracy: 0.7696\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.4864 - accuracy: 0.7719\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.5070 - accuracy: 0.7557\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4819 - accuracy: 0.7841\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.4819 - accuracy: 0.7729\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4663 - accuracy: 0.8019\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.4764 - accuracy: 0.7821\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 64s 477ms/step - loss: 0.4501 - accuracy: 0.7987\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4622 - accuracy: 0.7927\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.4378 - accuracy: 0.8052\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.4523 - accuracy: 0.8047\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4220 - accuracy: 0.8117\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4415 - accuracy: 0.8070\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4253 - accuracy: 0.8067\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4229 - accuracy: 0.8195\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 68s 513ms/step - loss: 0.4472 - accuracy: 0.8037\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 64s 480ms/step - loss: 0.4196 - accuracy: 0.8070\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 64s 480ms/step - loss: 0.4075 - accuracy: 0.8268\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4469 - accuracy: 0.8128\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4296 - accuracy: 0.8150\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 64s 480ms/step - loss: 0.4046 - accuracy: 0.8198\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4122 - accuracy: 0.8313\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4277 - accuracy: 0.8183\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.3997 - accuracy: 0.8238\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4415 - accuracy: 0.8150\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 69s 518ms/step - loss: 0.4050 - accuracy: 0.8348\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 63s 475ms/step - loss: 0.4091 - accuracy: 0.8381\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.4117 - accuracy: 0.8226\n",
            "Epoch 41/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4138 - accuracy: 0.8376\n",
            "Epoch 42/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4196 - accuracy: 0.8251\n",
            "Epoch 43/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.3921 - accuracy: 0.8394\n",
            "Epoch 44/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.3857 - accuracy: 0.8230\n",
            "Epoch 45/50\n",
            "133/133 [==============================] - 63s 476ms/step - loss: 0.3910 - accuracy: 0.8446\n",
            "Epoch 46/50\n",
            "133/133 [==============================] - 63s 477ms/step - loss: 0.4059 - accuracy: 0.8328\n",
            "Epoch 47/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4088 - accuracy: 0.8308\n",
            "Epoch 48/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.3951 - accuracy: 0.8384\n",
            "Epoch 49/50\n",
            "133/133 [==============================] - 64s 479ms/step - loss: 0.4246 - accuracy: 0.8288\n",
            "Epoch 50/50\n",
            "133/133 [==============================] - 64s 478ms/step - loss: 0.4141 - accuracy: 0.8391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1ba0797748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4GLdUPANV8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}